{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### План\n",
    "* Обучение и чиcтая оптимизация   \n",
    "* Проблемы градиентного спуска \n",
    "* Методы оптимизации\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение vs чистая оптимизация\n",
    "Алгоритмы оптимизации, используемые для обучения глубоких моделей, отличаются от традиционных алгоритмов оптимизации:\n",
    "\n",
    "* Нас интересует некоторая мера качества $ P $, определяется относительно тестового набора и может оказаться вычислительно сложной,   мы оптимизируем $ P $ косвенно. Мы уменьшаем другую функцию стоимости $ J(θ) $ в надежде, что при этом улучшится и P.\n",
    "* Алгоритмы оптимизации для обучения глубоких моделей обычно включают специализации для конкретной структуры целевых функций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Минимизация эмпирического риска\n",
    "Большинство алгоритмов машинного обучения в том или ином виде включает оптимизацию, т. е. нахождение минимума или максимума функции.\n",
    "Обычно задачу оптимизации формулируют в терминах нахождения минимума функции потерь/стоимости/ошибок – $ J(f(x, \\theta), y ) $.  $ \\theta^* = \\underset{\\theta}{\\operatorname{arg min}} J( f(x;\\theta), y) $ - где $ \\theta^* $ - целевые параметры алгоритма\n",
    "\n",
    "Типичную функцию стоимости можно представить в виде среднего по обучающему набору:\n",
    "\n",
    "$ J(\\theta) = \\mathop{\\mathbb{E}}_{(x,y)\\sim{\\hat p_{data}}} L( f(x, \\theta), у) $\n",
    "\n",
    "* $ L $  – функция потерь на одном примере\n",
    "* $ f(x; θ) $  – предсказанный выход для входа $ x $, \n",
    "* $ \\hat p_{data} $ – эмпирическое распределение.\n",
    "\n",
    "Обычно предпочитают минимизировать функцию где математическое ожидание берется по порождающему распределению pdata, а не просто по конечному обучающему набору:\n",
    "\n",
    "$ J(\\theta)^* = \\mathop{\\mathbb{E}}_{(x,y)\\sim{p_{data}}} L( f(x, \\theta), у) $\n",
    "\n",
    "* $ \\mathop{\\mathbb{E}}_{(x,y)\\sim{p_{data}}} $  - матожидание ошибки обобщения по истинному распределению $ p_{data} $ - *_риск_* , мы хотим его уменьшить.\n",
    "\n",
    "* при известном $ p_{data} $ - минимизация риска $ \\mathop{\\mathbb{E}}_{(x,y)\\sim{p_{data}}} $ - задача оптимизации  \n",
    "* мы заменяем $ p(x, y) $  на $ \\hat p(х, у) $ - посчитанному по обучающему сету. \n",
    " $$ => $$\n",
    "\n",
    "* минимизируем *_эмпирический риск_*, т.е. ошибку обобщения на обучающем сете $ \\large \\mathop{\\mathbb{E}}_{(x,y)\\sim{\\hat p_{data}(x, y)}} [L(f(x;\\theta), y)]= {1\\over m}  \\sum \\limits_{i=1} ^m {L(f(x^i; \\theta), y)}$\n",
    "\n",
    "m - количество обучающих примеров\n",
    "\n",
    "Таким образом, мы оптимизируем не риск, а эмпирический риск.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сурогатные функции потерь\n",
    "Иногда реально интересующая нас функция потерь и та, что может быть эффективно оптимизирована, – «две большие разницы».\n",
    "\n",
    "Пример:\n",
    "* $ \\large R(f) = \\mathop{\\mathbb{E}}[\\mathop{\\mathbb{1}}(sign(f(X)) \\ne Y )]. $ -  функция риска для бинарной классификации \n",
    "* $ \\large CE = - \\sum \\limits_{x} {y * log(p(x, \\theta))} $ - кроссэнтропия по классам\n",
    "\n",
    "В некоторых случаях суррогатная функция потерь позволяет достичь даже больших успехов в обучении. Ошибка может падать на тесте даже если на обучающем сете мы получили 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пакеты и мини-пакеты\n",
    "В обучении целевая функция представления в виде суммы по обучающим примерам, т.е. ошибка вычисляется не по всему сету (пакет) а по какомуто подмножеству обучающих примеров. Затем вычисляем градиент и обновление параметров  \n",
    "Пример,оценка максимального правдоподобия:\n",
    "* $ \\large \\theta_{ML} = \\underset{\\theta}{\\operatorname{arg max}} \\sum \\limits_{i=1}^m p_{model}(x^i, y^i; \\theta) $\n",
    "\n",
    "Максимизация эквивлентна максимизации матожидания эмпирического распределения функции стоимости: \n",
    "* $ \\large J(\\theta) = \\mathop{\\mathbb{E}}_{(x,y)\\sim \\hat p_{data}} log \\space p_{model}(x, y; \\theta)$\n",
    "\n",
    "Большинство свойств целевой функции, используемой в алгоритмах оптимизации, выражаются в терминах мат ожидания:\n",
    "* $ \\large \\nabla_{\\theta} J(\\theta) =  \\mathop{\\mathbb{E}}_{(x,y)\\sim \\hat p_{data}} \\nabla_{\\theta}log \\space p_{model}(x, y; \\theta) $\n",
    "\n",
    "#### Важно, что на практике вычисление точного градиента по полному сету будет стоить очень дорого  \n",
    "\n",
    "Стандартная ошибка среднего оцененная по выборке $ n $:\n",
    "* $ \\large SE(\\hat \\mu) = \\sqrt{Var \\Bigg [{{1\\over{m}} \\sum \\limits_{i=1}^m{x^i}}} \\Bigg] = {\\sigma \\over \\sqrt{m}} $\n",
    "\n",
    "!!! точность оценки градиента с увеличением объема выборки растет медленнее, чем линейно. Увеличивая размер выборки в 1000, замедлимся в 1000 раз, но получаем оценку нрадиента всего лишь в 10 раз точнее,\n",
    "\n",
    "Вторая причина работать мини батчами - наличие повторяющихся примеров в обучающем сете, которые дают похожий вклад в градиент\n",
    "\n",
    "Для обучения на практике нужно выбиратьчто что-то среднее между пакетным и онлайн обучением.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### На размер мини-пакета оказывают влияние следующие факторы:\n",
    "    \n",
    "* чем больше пакет, тем точнее оценка градиента, но зависимость хуже линейной;\n",
    "* если пакет очень мал, то не удается в полной мере задействовать преимущества многоядерной архитектуры.\n",
    "* Для многих аппаратных конфигураций размер пакета – ограничивающий фактор;\n",
    "* небольшие пакеты могут дать эффект регуляризации (Wilson and Martinez, 2003), быть может, из-за шума, который они вносят в процесс обучения.\n",
    "* Ошибка обобщения часто оказывается наилучшей для пакета размера 1. Но для обучения с таким маленьким размером пакета нужна небольшая скорость обучения для обеспечения устойчивости из-за высокой дисперсии оценки градиента. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение минипакетами\n",
    "* В зависимости от алгоритма обучения будет использоваться различная информация, например, методы первого порядка более устойчивы к шуму и могут работать на пакетах в 100 примерах, методы второго порядка менее устойчивы и требуют 10000 примеров в пакете.\n",
    "* нужно максимально убирать зависимости между примерами и пакетами, для вычисления несмещенной оценки градиента. Для этого нужно выбирать мини-пакеты слцчайно.\n",
    "* для большого количества данных с миллиардами примеров, сложно получитьвыборку пакетов понастоящему случайно, поэтому набор перемешивают один раз и втаком виде подают алгоритму. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проблемы оптимизации "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Плохая обусловленность\n",
    "* Самая известная проблема это плохая обусловленность матрицы Гессе: $ \\large H $, приводит к застреванию SGD,когда малые шаги увеличивают функцию стоимости.\n",
    "\n",
    "Матрица Гессе для функции нескольких переменных: $ \\large H(f(x)_{i,j}) = \\frac {\\partial^2} {\\partial x_i\\partial x_j}f(x) $\n",
    "\n",
    "Если функцию, которую мы апроксимируем разложить в ряд тейлора до членов второго порядка в окрестности $ x_0$ :\n",
    "\n",
    "$\\large f(x) \\approx f(x_0) + (x - x_0)^T \\space g + \\frac{1}{2} \\space (x-x_0)^T \\space H \\space (x-x_0) $\n",
    "\n",
    "* $  g $ - градиент, а $  H$ - гессиан в точке  $ x_0 $\n",
    "* если $ \\epsilon $ - шаг обучения, то новыя точка $ x = x_0 - \\epsilon \\space g$\n",
    "\n",
    "$\\large f(x - \\epsilon g) \\approx f(x_0) -  \\epsilon g^T g + \\frac{1}{2} \\epsilon^2 g^TH g $\n",
    "\n",
    "Можно видеть, что шаг градиентного спуска $ -\\epsilon g $ увеличивает стоимость на $ \\frac{1}{2} \\epsilon^2 g^TH g - \\epsilon g^T g $ \n",
    "\n",
    "Плохая обусловленность градиента становится проблемой, когда  $ \\frac{1}{2} \\epsilon^2 g^TH g $ больше $ \\epsilon g^T g $ . \n",
    "\n",
    "* квадрат нормы градиента $ g^T g $ и член $  g^THg $ - могут служить мониторингом плохой обусловленности градиента\n",
    "* норма градиента не сильно уменьшается за время обучения, тогда как член $ g^⏉Hg $ растет на порядок\n",
    "* В результате обучение происходит очень медленно, несмотря на большой градиент, т. к. приходится уменьшать скоростьобучения, чтобы компенсировать еще большую кривизну функции.\n",
    "\n",
    "    <img src=\"./img/gradient_grow.png\" width=800>\n",
    "    \n",
    "Градиентный спуск часто не находит никакой критической\n",
    "точки. В этом примере норма градиента возрастает на протяжении всего\n",
    "процесса обучения  нейронной сети. По идее градиент должен уменьшаться если алгоритм сходится к критической точке.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Локалтные минимумы\n",
    "* Выпуклую оптимизацию можно свести к нахождению локального минимума. Гарантируется, что любой локальный минимум является глобальным\n",
    "* У нейронных сетей (невыпуклых функций) может быть множество локальных минимумов из-за проблемы __идентифицируемости модели__.\n",
    "\n",
    "_Модель иентифицируема, если существует достаточно большой набор обучающих данных, который может исключить  все конфигурации параметров кроме одной._ \n",
    "* модели с латеньными переменными часто не являются идентифицируемыми. Можно  получить эквивалентные модели, меняя латентные переменные местами. \n",
    "* проблема идентифицируемости модели означает, что функция стоимости нейронной сети может иметь очень большое, даже несчетное, множество локальных минимумов\n",
    "* если значение функции стоимости велико в локально минимуме, то это проблема, но в большинстве случаев обучение находит локальный минимум с низкой стоимостью, и это не является проблеммой\n",
    "\n",
    "<img src=\"./img/local_minima.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Седловые точки и плато\n",
    "<img src=\"./img/saddle_point.png\" width=500>\n",
    "\n",
    "* Для многих невыпуклых функций в многомерных пространствах локальные минимумы (и максимумы) встречаются гораздо реже других точек с нулевым градиентом: седловых точек. В одних точках в окрестности седловой стоимость выше, чем в седловой точке, в других – ниже.\n",
    "\n",
    "* В седловой точке матрица Гессе имеет как положительные, так и отрицательные собственные значения.\n",
    "\n",
    "* В точках, лежащих вдоль собственных векторов с положительными собственными значениями, стоимость выше, чем в седловой точке, а в точках, лежащих вдоль собственных векторов с отрицательными собственными значениями, – ниже.\n",
    "\n",
    "<img src=\"./img/saddle_point_2D.png\" width=500>\n",
    "\n",
    "* Для функции $ f : ℝ^n → ℝ $ в пространстве высокой размерности ожидаемое отношение числа седловых точек к числу локальных максимумов растет экспоненциально с ростом n. \n",
    "\n",
    "* Градиент часто оказывается очень мал в окрестности седловой точки. С другой стороны, есть эмпирические свидетельства в пользу того, что метод градиентного спуска во многих случаях способен выйти из седловой точки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Утесы и резко расстущие градиенты\n",
    "<img src=\"./img/exploding_grad.png\" width=500>\n",
    "\n",
    "* В нейронных сетях с большим числом слоев часто встречаются очень крутые участки, напоминающие утесы. Это связано с перемножением нескольких больших весов, например, рекурентные сети. \n",
    "* На стене особенно крутого утеса шаг обновления градиента может привести к очень сильному изменению параметров, что обычно заканчивается «срывом».\n",
    "\n",
    "__Например__\n",
    "* предположим, что граф вычислений содержит путь, состоящий из повторных умножений на матрицу $ W $\n",
    "* через t - шагов получаем матрицу $ W^t $ \n",
    "* спектральное разложение W имеет вид $ W = V diag(λ)V^{-1} $.\n",
    "* $ W^t = (V diag(λ)V^{-1})^t = V diag(λ)^t V^–1 $\n",
    "* все $ \\lambda_i $ либо возрастают при $ \\lambda_i > 1 $ - __взрыв__ либо __затухают__ при $ \\lambda_i < 1 $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основные алгоритмы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классический SGD (онлайн):\n",
    "$$\n",
    "\\large\n",
    "\\theta_t = \\theta_{t-1} - \\lambda \\frac{\\partial L}{\\partial \\theta}\n",
    "$$\n",
    "\n",
    "Количество примеров в обучающем датасете может быть достаточно большим или вообще неограничено. <br>\n",
    "\n",
    " - В данном случае, для одной итерации нам надо пройти по всему датасету. <br>\n",
    " - Можно обучаться \"на лету\" на вновь поступающих примерах.<br>\n",
    " - Нередко шаги могут уводить нас от минимума, в силу того, что мы смотрим только на один пример\n",
    "\n",
    "### Mini-batch SGD, позволяет использовать ресурсы GPU эффективней\n",
    "Делим данные на части небольшого размера $B = \\{1000,256,64 ...\\}$<br>\n",
    "**Тогда получаем вход:<br>**\n",
    "$\\large x = [\\overbrace{x_1, x_2, x_3, ... x_B}^{x^{\\{1\\}}}, \\overbrace{x_{B+1}, x_{B+2}, x_{B+3}, ... x_{2*B}}^{x^{\\{2\\}}}, ... , x_M]  \\leftarrow $ последовательность матриц размером $C \\times  B$, $C$ - размер входного вектора<br>\n",
    "**Выход:<br>**\n",
    "$\\large y = [\\overbrace{y_1, y_2, y_3,...,y_B}^{y^{\\{1\\}}},..., ... , y_M] \\leftarrow $ последовательность матриц размером $A \\times  B$, $A$ - размер выходного вектора<br>\n",
    "\n",
    "Функция ошибки усредняется не по всем примерам, а только по батчу размера $B$\n",
    "$$\n",
    "\\overset{\\wedge}{\\large J}(f(x;\\theta),  y) = \\frac {1} {B} \\sum_{i=1}^B {\\large L(\\tilde{y_i}, y_i)}\n",
    "$$\n",
    "Получаем следующую функцию отимизации для каждого шага градиентного спуска\n",
    "$$\n",
    "\\large\n",
    "\\theta_t = \\theta_{t-1} - \\epsilon \\frac{\\partial \\overset{\\wedge}{\\large J}}{\\partial \\theta}\n",
    "$$\n",
    "\n",
    "** Вопрос: **\n",
    "Почему при обучении с полным батчем график обучения гладкий, а при использовании мини батча сильно  осциллирует?\n",
    "<img src=\"./img/minibatch_vs_batch_gd.png\" width=800>\n",
    "\n",
    "Как выглядит градиент в пространстве весов \n",
    "1. Для режима online SGD и для обучения с GD\n",
    "<img src=\"./img/batch_vs_sgd.png\" width=800>\n",
    "2. Для режима mini-batch SGD и для обучения с online SGD\n",
    "<img src=\"./img/minibatch_vs_batch_sgd.png\" width=800>\n",
    "\n",
    "* Основной параметр алгоритма SGD – скорость обучения $ \\epsilon $. На практике необходимо постепенно уменьшать ее со временем.   \n",
    "- $ ε_k $ скорость обучения на k-ой итерации.\n",
    "\n",
    "Достаточные условия сходимости SGD имеют вид:\n",
    "\n",
    "$ \\large \\sum \\limits_{k=1}^{\\infty} \\epsilon_k = \\infty $\n",
    "\n",
    "$ \\large \\sum \\limits_{k=1}^{\\infty} \\epsilon_k^2 < \\infty $\n",
    "\n",
    "* На практике скорость обучения обычно уменьшают линейно до итерации с номером τ:\n",
    " $ \\large ε_k = (1 – α)ε_0 + α \\space ε_τ $; \n",
    "где $ α = k/τ $ . После τ-й итерации ε остается постоянным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD + Momentum (Импульсный метод)\n",
    "\n",
    "В импульсном алгоритме вычисляется экспоненциально затухающее скользящее среднее прошлых градиентов и продолжается движение в этом направлении\n",
    "\n",
    "* Импульсный метод призван решить две проблемы: плохую обусловленность матрицы Гессе и дисперсию стохастического градиента.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    " <td>\n",
    "1. Градиент с моментом__\n",
    "<img src=\"./img/sgd_momentum.png\" width=400>\n",
    "     </td><td>\n",
    "2. Градиент без момента\n",
    "<img src=\"./img/sgd.png\" width=400>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "* Момент это экспоненциальное скользящее среднее по $ \\large \\approx \\frac{1}{1-\\beta}$ - последним итерациям \n",
    "\n",
    "$$\n",
    "\\Large\n",
    "\\begin{align}\n",
    "g_t &= \\nabla_{\\theta} \\overset{\\wedge}{\\large J}\\left(f(x, \\theta),y \\right) - градиент \\\\\n",
    "m_t &= \\beta m_{t-1} - (1- \\beta) g_t, \\ где \\  \\beta - параметр\\ обучения \\\\\n",
    "m_t &= \\alpha m_{t-1} - \\epsilon g_t, \\ альтернативная \\ форма \\ записи \\\\\n",
    "\\theta_t &= \\theta_{t-1} + m_t\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "SGD - методом нестерова\n",
    "\n",
    "$\n",
    "\\large \n",
    "\\begin{align}\n",
    "1. \\ выполняем \\ проиежуточный  \\ расчет \\  параметров: \\\n",
    " \\tilde \\theta = \\theta + \\alpha \\ m_{t-1}\n",
    " \\\\ \n",
    "2. \\ вычисляем \\  градиент \\ в \\ промежуточной \\  точке: \\\n",
    "g_t &= \\nabla_{\\theta} \\overset{\\wedge}{\\large J}\\left(f(x, \\tilde \\theta),y \\right)\n",
    "\\\\\n",
    "3. \\ вычисляем \\ обновление \\ скорости: \\  m_t ← α  v_{t-1} – ε  g_t\n",
    "\\\\\n",
    "4. \\ обновляем \\ параметры: \\ \\theta_t &= \\theta_{t-1} + m_t\n",
    " \\end{align}\n",
    "$\n",
    "\n",
    "* В случае выпуклой оптимизации пакетным градиентным спуском метод Нестерова повышает скорость сходимости ошибки превышения с O(1/k) (после k шагов) до O(1/k2). К сожалению, в случае стохастического градиентного спуска метод Нестерова не улучшает скорости сходимости.\n",
    "\n",
    "<img src=\"./img/4.gif\" width=500>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы с адаптивной скоростью обучения\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSProp (Root Mean Square Propagation)\n",
    "#### Решаем проблемму редких признаков, ускоряя схождение.\n",
    "$$\n",
    "\\Large\n",
    "\\begin{align}\n",
    "v_t &- скользящее\\ среднее\\ по \\ g^2 \\\\\n",
    "v_t &= \\beta * v_{t-1} +  (1-\\beta)* g_{t}^2  \\\\\n",
    "\\theta &= \\theta - \\lambda \\frac{1}{\\sqrt{v_t + \\epsilon}} g_t\n",
    "\\end{align}\n",
    "$$\n",
    "__Долго накапливает начальные значения__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam (Adaptive Moment Estimation) \n",
    "\n",
    "### Adam = SGD + Momentum + RMSProp\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\begin{align}\n",
    "\\begin{cases}\n",
    "m_t &= \\alpha \\ m_{t-1} + (1 - \\alpha)\\ g - оценка \\ момента \\\\ \n",
    "v_t &= \\beta \\ v_{t-1} +  (1-\\beta)\\ g_{t}^2  - оценка \\ второго\\ момента \\\\\n",
    "\\end{cases}\n",
    "\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "### исправляем  недостаток  RMSProp  корректируем биас на начальных  итерациях\n",
    "$$\n",
    "\\large\n",
    "\\begin{align}\n",
    "\\hat{m_t} &= \\frac{m_t}{1 - \\alpha^t} \\\\\n",
    "\\hat{v_t} &= \\frac{v_t}{1 - \\beta^t} \\\\\n",
    "\\theta_t &= \\theta_{t-1} -  \\frac{\\lambda}{\\sqrt{\\hat{v_t} + \\epsilon}}\\hat{m_t} \\\\\n",
    "\\ выразим\\ step\\_size \\ через \\ \\alpha \\ и \\ \\beta \\\\\n",
    "\\ step\\_size =  \\lambda \\frac {({1 - \\beta^t})^{\\frac{1}{2}}}{{1 - \\alpha^t}} \\\\ \n",
    "\\theta_t &= \\theta_{t-1} -  \\frac{step\\_size}{\\sqrt{v_t + \\epsilon}}\\times m_t \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./imgs/6.gif\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример градиента в седловой точке \n",
    "<img src=\"./img/saddle_point_algos.gif\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
