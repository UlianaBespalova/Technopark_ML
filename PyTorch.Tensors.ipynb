{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.tensor\n",
    "==========================\n",
    "\n",
    "Тензоры - это специализированная структура данных похожая на массивы и матрицы. В пакете PyTorch тензоры применяются для хранения и обработки входов и выходов нейросетевых моделей, а так же их весов.\n",
    "\n",
    "Тензорвы очень похожи на ndarray пакета numpy, за исключением того, что они подходят для рассчетов с использованием GPU(NVIDIA/AMD) и поддерживают механизм автоматического дифференцирования Autograd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание тензоров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим неинициализированны тензор. Обратите внимание, что по умолчанию все тензоры имеют тип `torch.FloatTensor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor type : <class 'torch.Tensor'>\n",
      "Tensor data type : torch.FloatTensor\n",
      "tensor([[ 0.0000e+00,  4.4766e+00,  9.3233e-02,  1.8976e-01],\n",
      "        [ 4.0042e-29, -1.5846e+29,  4.0045e-29,  8.5899e+09],\n",
      "        [ 4.2039e-45, -3.6893e+19,  4.0039e-29, -8.5899e+09]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(3,4)\n",
    "print(f\"Tensor type : {type(x)}\")\n",
    "print(f\"Tensor data type : {x.type()}\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим тензоры с константными и случайными значениями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros : tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "ones : tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "random : tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n"
     ]
    }
   ],
   "source": [
    "zeros = torch.zeros(2, 3)\n",
    "print(f\"zeros : {zeros}\")\n",
    "\n",
    "ones = torch.ones(2, 3)\n",
    "print(f\"ones : {ones}\")\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "random = torch.rand(2, 3)\n",
    "print(f\"random : {random}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Внимание__, если вам нужна воспроизводимость результатов случайной инициализации, то не забывайте использовать `torch.manual_seed()`\n",
    "Более подробно о воспроизводимости <a href=\"https://pytorch.org/docs/stable/notes/randomness.html\"> тут <a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random1 : tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "random2 : tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n",
      "random3 : tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "random4 : tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1729)\n",
    "random1 = torch.rand(2, 3)\n",
    "print(f\"random1 : {random1}\")\n",
    "\n",
    "random2 = torch.rand(2, 3)\n",
    "print(f\"random2 : {random2}\")\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "random3 = torch.rand(2, 3)\n",
    "print(f\"random3 : {random3}\")\n",
    "\n",
    "random4 = torch.rand(2, 3)\n",
    "print(f\"random4 : {random4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же в PyTorch есть возможность наследовать размерности других тензоров при создании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0.6128, 0.1519, 0.0453],\n",
      "         [0.5035, 0.9978, 0.3884]],\n",
      "\n",
      "        [[0.6929, 0.1703, 0.1384],\n",
      "         [0.4759, 0.7481, 0.0361]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0.6128, 0.1519, 0.0453],\n",
      "         [0.5035, 0.9978, 0.3884]],\n",
      "\n",
      "        [[0.6929, 0.1703, 0.1384],\n",
      "         [0.4759, 0.7481, 0.0361]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0.6128, 0.1519, 0.0453],\n",
      "         [0.5035, 0.9978, 0.3884]],\n",
      "\n",
      "        [[0.6929, 0.1703, 0.1384],\n",
      "         [0.4759, 0.7481, 0.0361]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(2, 2, 3)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "\n",
    "empty_like_x = torch.empty_like(x)\n",
    "print(empty_like_x.shape)\n",
    "print(empty_like_x)\n",
    "\n",
    "zeros_like_x = torch.zeros_like(x)\n",
    "print(zeros_like_x.shape)\n",
    "print(zeros_like_x)\n",
    "\n",
    "ones_like_x = torch.ones_like(x)\n",
    "print(ones_like_x.shape)\n",
    "print(ones_like_x)\n",
    "\n",
    "rand_like_x = torch.rand_like(x)\n",
    "print(rand_like_x.shape)\n",
    "print(rand_like_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте создадим несколько тензоров из типов данных самого python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.1416, 2.7183],\n",
      "        [1.6180, 0.0073]])\n",
      "tensor([ 2,  3,  5,  7, 11, 13, 17, 19])\n",
      "tensor([[2, 4, 6],\n",
      "        [3, 6, 9]])\n"
     ]
    }
   ],
   "source": [
    "some_constants = torch.tensor([[3.1415926, 2.71828], [1.61803, 0.0072897]])\n",
    "print(some_constants)\n",
    "\n",
    "some_integers = torch.tensor((2, 3, 5, 7, 11, 13, 17, 19))\n",
    "print(some_integers)\n",
    "\n",
    "more_integers = torch.tensor(((2, 4, 6), [3, 6, 9]))\n",
    "print(more_integers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Типы данных тензоров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В PyTorch тензоры могут хранить различные типы данных в рамках одного объекта, т.е. один `torch.tensor` может содержать внутри себя только один тип данных. Существующие типы данных в PyTorch:\n",
    "<ul>\n",
    "<li>torch.bool</li>\n",
    "<li>torch.int8</li>\n",
    "<li>torch.uint8</li>\n",
    "<li>torch.int16</li>\n",
    "<li>torch.uint16</li>\n",
    "<li>torch.int32</li>\n",
    "<li>torch.uint32</li>\n",
    "<li>torch.half - fp16 </li>\n",
    "<li>torch.float</li>\n",
    "<li>torch.double</li>\n",
    "<li>torch.bfloat - <a href=\"https://en.wikichip.org/wiki/brain_floating-point_format\"> brain float <a> </li> \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int16)\n",
      "tensor([[ 0.9956,  1.4148,  5.8364],\n",
      "        [11.2406, 11.2083, 11.6692]], dtype=torch.float64)\n",
      "tensor([[ 0,  1,  5],\n",
      "        [11, 11, 11]], dtype=torch.int32)\n",
      "tensor([[ 0.,  1.,  5.],\n",
      "        [11., 11., 11.]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((2, 3), dtype=torch.int16)\n",
    "print(a)\n",
    "\n",
    "b = torch.rand((2, 3), dtype=torch.float64) * 20.\n",
    "print(b)\n",
    "\n",
    "c = b.to(torch.int32)\n",
    "print(c)\n",
    "\n",
    "d = c.to(torch.half)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Математические и логические операции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Операции со скалярами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[2., 2.],\n",
      "        [2., 2.]])\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[4., 4.],\n",
      "        [4., 4.]])\n",
      "tensor([[1.4142, 1.4142],\n",
      "        [1.4142, 1.4142]])\n"
     ]
    }
   ],
   "source": [
    "ones = torch.zeros(2, 2) + 1\n",
    "twos = torch.ones(2, 2) * 2\n",
    "threes = (torch.ones(2, 2) * 7 - 1) / 2\n",
    "fours = twos ** 2\n",
    "sqrt2s = twos ** 0.5\n",
    "\n",
    "print(ones)\n",
    "print(twos)\n",
    "print(threes)\n",
    "print(fours)\n",
    "print(sqrt2s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Такие же операции между парами тензоров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  4.],\n",
      "        [ 8., 16.]])\n",
      "tensor([[5., 5.],\n",
      "        [5., 5.]])\n",
      "tensor([[12., 12.],\n",
      "        [12., 12.]])\n"
     ]
    }
   ],
   "source": [
    "powers2 = twos ** torch.tensor([[1, 2], [3, 4]])\n",
    "print(powers2)\n",
    "\n",
    "fives = ones + fours\n",
    "print(fives)\n",
    "\n",
    "dozens = threes * fours\n",
    "print(dozens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот что будет, если размерности тензоров не совпадут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occured : The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 3)\n",
    "b = torch.rand(3, 2)\n",
    "\n",
    "try:\n",
    "    print(a * b)\n",
    "except Exception as e:\n",
    "    print(f\"Error occured : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting операции над `torch.tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2024, 0.5731, 0.7191, 0.4067],\n",
      "        [0.7301, 0.6276, 0.7357, 0.0381]])\n",
      "tensor([[0.2024, 1.1461, 2.1573, 1.6268],\n",
      "        [0.7301, 1.2551, 2.2072, 0.1524]])\n"
     ]
    }
   ],
   "source": [
    "rand = torch.rand(2, 4)\n",
    "aranged = rand * (torch.arange(4) + 1)\n",
    "\n",
    "print(rand)\n",
    "print(aranged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В примере выше мы построчно перемножили тензор из случайных значений с тензором `torch.tensor([1, 2, 3 ,4])`. Это крайне полезная и нужная операция в Deep Learning. Вот правила, по которым она работает:\n",
    "\n",
    " - Каждый из тензоров должен иметь хотя бы одну ненулевую размерность. Нулевые тензоры не бродкастятся!\n",
    " - Сравниваем размерности 2-х тензоров от последней к начальной:\n",
    " - * Каждая из размерностей должна быть равна ИЛИ\n",
    " - * Одна из размерностей должна быть равна 1, ИЛИ\n",
    " - * Размерность отсутствует в одном из тензоров.\n",
    " \n",
    " Рассмотрим примеры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2138, 0.5395],\n",
      "         [0.3686, 0.4007],\n",
      "         [0.7220, 0.8217]],\n",
      "\n",
      "        [[0.2138, 0.5395],\n",
      "         [0.3686, 0.4007],\n",
      "         [0.7220, 0.8217]],\n",
      "\n",
      "        [[0.2138, 0.5395],\n",
      "         [0.3686, 0.4007],\n",
      "         [0.7220, 0.8217]],\n",
      "\n",
      "        [[0.2138, 0.5395],\n",
      "         [0.3686, 0.4007],\n",
      "         [0.7220, 0.8217]]])\n",
      "tensor([[[0.2612, 0.2612],\n",
      "         [0.7375, 0.7375],\n",
      "         [0.8328, 0.8328]],\n",
      "\n",
      "        [[0.2612, 0.2612],\n",
      "         [0.7375, 0.7375],\n",
      "         [0.8328, 0.8328]],\n",
      "\n",
      "        [[0.2612, 0.2612],\n",
      "         [0.7375, 0.7375],\n",
      "         [0.8328, 0.8328]],\n",
      "\n",
      "        [[0.2612, 0.2612],\n",
      "         [0.7375, 0.7375],\n",
      "         [0.8328, 0.8328]]])\n",
      "tensor([[[0.8444, 0.2941],\n",
      "         [0.8444, 0.2941],\n",
      "         [0.8444, 0.2941]],\n",
      "\n",
      "        [[0.8444, 0.2941],\n",
      "         [0.8444, 0.2941],\n",
      "         [0.8444, 0.2941]],\n",
      "\n",
      "        [[0.8444, 0.2941],\n",
      "         [0.8444, 0.2941],\n",
      "         [0.8444, 0.2941]],\n",
      "\n",
      "        [[0.8444, 0.2941],\n",
      "         [0.8444, 0.2941],\n",
      "         [0.8444, 0.2941]]])\n"
     ]
    }
   ],
   "source": [
    "a =     torch.ones(4, 3, 2)\n",
    "\n",
    "b = a * torch.rand(   3, 2) # 3rd & 2nd dims identical to a, dim 1 absent\n",
    "print(b)\n",
    "\n",
    "c = a * torch.rand(   3, 1) # 3rd dim = 1, 2nd dim identical to a \n",
    "print(c)\n",
    "\n",
    "d = a * torch.rand(   1, 2) # 3rd dim identical to a, 2nd dim = 1\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже представлены другие математические и логические операции с тензорами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common functions:\n",
      "tensor([[0.2424, 0.0866, 0.8702, 0.3355],\n",
      "        [0.5652, 0.7337, 0.9955, 0.0110]])\n",
      "tensor([[-0., -0., -0., 1.],\n",
      "        [1., -0., -0., -0.]])\n",
      "tensor([[-1., -1., -1.,  0.],\n",
      "        [ 0., -1., -1., -1.]])\n",
      "tensor([[-0.2424, -0.0866, -0.5000,  0.3355],\n",
      "        [ 0.5000, -0.5000, -0.5000, -0.0110]])\n",
      "\n",
      "Sine and arcsine:\n",
      "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
      "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
      "tensor([0.0000, 0.7854, 1.5708, 0.7854])\n",
      "\n",
      "Bitwise XOR:\n",
      "tensor([3, 2, 1])\n",
      "\n",
      "Broadcasted, element-wise equality comparison:\n",
      "tensor([[ True, False],\n",
      "        [False, False]])\n",
      "\n",
      "Reduction ops:\n",
      "tensor(4.)\n",
      "4.0\n",
      "tensor(2.5000)\n",
      "tensor(1.2910)\n",
      "tensor(24.)\n",
      "tensor([1, 2])\n",
      "\n",
      "Vectors & Matrices:\n",
      "tensor([ 0.,  0., -1.])\n",
      "tensor([[0.3857, 0.9883],\n",
      "        [0.4762, 0.7242]])\n",
      "tensor([[1.1572, 2.9650],\n",
      "        [1.4287, 2.1726]])\n",
      "torch.return_types.svd(\n",
      "U=tensor([[-0.7758, -0.6310],\n",
      "        [-0.6310,  0.7758]]),\n",
      "S=tensor([4.0883, 0.4211]),\n",
      "V=tensor([[-0.4401,  0.8980],\n",
      "        [-0.8980, -0.4401]]))\n"
     ]
    }
   ],
   "source": [
    "# common functions\n",
    "a = torch.rand(2, 4) * 2 - 1\n",
    "print('Common functions:')\n",
    "print(torch.abs(a))\n",
    "print(torch.ceil(a))\n",
    "print(torch.floor(a))\n",
    "print(torch.clamp(a, -0.5, 0.5))\n",
    "\n",
    "# trigonometric functions and their inverses\n",
    "angles = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
    "sines = torch.sin(angles)\n",
    "inverses = torch.asin(sines)\n",
    "print('\\nSine and arcsine:')\n",
    "print(angles)\n",
    "print(sines)\n",
    "print(inverses)\n",
    "\n",
    "# bitwise operations\n",
    "print('\\nBitwise XOR:')\n",
    "b = torch.tensor([1, 5, 11])\n",
    "c = torch.tensor([2, 7, 10])\n",
    "print(torch.bitwise_xor(b, c))\n",
    "\n",
    "# comparisons:\n",
    "print('\\nBroadcasted, element-wise equality comparison:')\n",
    "d = torch.tensor([[1., 2.], [3., 4.]])\n",
    "e = torch.ones(1, 2)  # many comparison ops support broadcasting!\n",
    "print(torch.eq(d, e)) # returns a tensor of type bool\n",
    "\n",
    "# reductions:\n",
    "print('\\nReduction ops:')\n",
    "print(torch.max(d))        # returns a single-element tensor\n",
    "print(torch.max(d).item()) # extracts the value from the returned tensor\n",
    "print(torch.mean(d))       # average\n",
    "print(torch.std(d))        # standard deviation\n",
    "print(torch.prod(d))       # product of all numbers\n",
    "print(torch.unique(torch.tensor([1, 2, 1, 2, 1, 2]))) # filter unique elements\n",
    "\n",
    "# vector and linear algebra operations\n",
    "v1 = torch.tensor([1., 0., 0.])         # x unit vector\n",
    "v2 = torch.tensor([0., 1., 0.])         # y unit vector\n",
    "m1 = torch.rand(2, 2)                   # random matrix\n",
    "m2 = torch.tensor([[3., 0.], [0., 3.]]) # three times identity matrix\n",
    "\n",
    "print('\\nVectors & Matrices:')\n",
    "print(torch.cross(v2, v1)) # negative of z unit vector (v1 x v2 == -v2 x v1)\n",
    "print(m1)\n",
    "m3 = torch.matmul(m1, m2)\n",
    "print(m3)                  # 3 times m1\n",
    "print(torch.svd(m3))       # singular value decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Изменение тензоров без выделения памяти (inplace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как правило, любые операции над тензорами так или иначе приводят к выделению памяти. Часто бывает необходимо изменить тензор непосредственно, без создания нового объекта(читай выделения памяти)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
      "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
      "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
      "\n",
      "b:\n",
      "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
      "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
      "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
    "print('a:')\n",
    "print(a)\n",
    "print(torch.sin(a))   # this operation creates a new tensor in memory\n",
    "print(a)              # a has not changed\n",
    "\n",
    "b = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
    "print('\\nb:')\n",
    "print(b)\n",
    "print(torch.sin_(b))  # note the underscore\n",
    "print(b)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То же самое с обычными арифметическими операциями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.0776, 0.4004],\n",
      "        [0.9877, 0.0352]])\n",
      "\n",
      "After adding:\n",
      "tensor([[1.0776, 1.4004],\n",
      "        [1.9877, 1.0352]])\n",
      "tensor([[1.0776, 1.4004],\n",
      "        [1.9877, 1.0352]])\n",
      "tensor([[0.0776, 0.4004],\n",
      "        [0.9877, 0.0352]])\n",
      "\n",
      "After multiplying\n",
      "tensor([[0.0060, 0.1603],\n",
      "        [0.9756, 0.0012]])\n",
      "tensor([[0.0060, 0.1603],\n",
      "        [0.9756, 0.0012]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 2)\n",
    "b = torch.rand(2, 2)\n",
    "\n",
    "print('Before:')\n",
    "print(a)\n",
    "print(b)\n",
    "print('\\nAfter adding:')\n",
    "print(a.add_(b))\n",
    "print(a)\n",
    "print(b)\n",
    "print('\\nAfter multiplying')\n",
    "print(b.mul_(b))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из примеров выше видно, что inplace операции не принадлежат модулю `torch` и предоставляются непосредственно самими изменяемыми тензорами. При необходимости такого же поведения можно достичь встроенными методами модуля, при помощи атрибута `out`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[0.4101, 0.1728],\n",
      "        [0.8007, 0.7183]])\n",
      "tensor([[0.8441, 0.9004],\n",
      "        [0.3995, 0.6324]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 2)\n",
    "b = torch.rand(2, 2)\n",
    "c = torch.zeros(2, 2)\n",
    "old_id = id(c)\n",
    "\n",
    "print(c)\n",
    "d = torch.matmul(a, b, out=c)\n",
    "print(c)                # contents of c have changed\n",
    "\n",
    "assert c is d           # test c & d are same object, not just containing equal values\n",
    "assert id(c), old_id    # make sure that our new c is the same object as the old one\n",
    "\n",
    "torch.rand(2, 2, out=c) # works for creation too!\n",
    "print(c)                # c has changed again\n",
    "assert id(c), old_id    # still the same object!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Копирование тензоров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в обычном Python, присваивая переменной значение какого-либо тензора, мы присваиваем ссылку, само значение не копируется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1., 561.],\n",
      "        [  1.,   1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 2)\n",
    "b = a\n",
    "\n",
    "a[0][1] = 561  # we change a...\n",
    "print(b)       # ...and b is also altered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что делать, если мы хотим скопировать тензор? Все просто - клонируем его!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True],\n",
      "        [True, True]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 2)\n",
    "b = a.clone()\n",
    "\n",
    "assert b is not a      # different objects in memory...\n",
    "print(torch.eq(a, b))  # ...but still with the same contents!\n",
    "\n",
    "a[0][1] = 561          # a changes...\n",
    "print(b)               # ...but b is still all ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ВНИМАНИЕ__ при клонировании тензора, как показано выше, вместе со всем содержимым и клонируется и граф вычислений данного тензора. Что приведет к пробросу градиентов от клона к исходному вектору. Если вы не ожидаете данного поведения, то необходимо дополнительно использовать метод `detach()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9464, 0.0113],\n",
      "        [0.5183, 0.9807]], requires_grad=True)\n",
      "tensor([[0.9464, 0.0113],\n",
      "        [0.5183, 0.9807]], grad_fn=<CloneBackward0>)\n",
      "tensor([[0.9464, 0.0113],\n",
      "        [0.5183, 0.9807]])\n",
      "tensor([[0.9464, 0.0113],\n",
      "        [0.5183, 0.9807]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 2, requires_grad=True) # turn on autograd\n",
    "print(a)\n",
    "\n",
    "b = a.clone()\n",
    "print(b)\n",
    "\n",
    "c = a.detach().clone()\n",
    "print(c)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы PyTorch с GPU первоначально необходимо удостовериться, что GPU доступен."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, CPU only.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('We have a GPU!')\n",
    "else:\n",
    "    print('Sorry, CPU only.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При создании тензора возможно указать устройство, в памяти которого, он должен быть размещен. По-умолчанию, все тензоры размещаются на CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_rand : tensor([[0.6545, 0.4144],\n",
      "        [0.0696, 0.4648]]), cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    gpu_rand = torch.rand(2, 2, device='cuda')\n",
    "    print(f\"gpu_rand : {gpu_rand}, {gpu_rand.device}\")\n",
    "else:\n",
    "    cpu_rand = torch.rand(2, 2, device='cpu')\n",
    "    print(f\"cpu_rand : {cpu_rand}, {cpu_rand.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество доступных PyTorch GPU можно узнать при помощи: `torch.cuda.device_count()`. Если в системе более, чем одна GPU, то они могут быть обозначены строками: `device='cuda:0'`, `device='cuda:1'`.\n",
    "Для переноса уже существующего тензора на то или иное устройство, необходимо использовать метод `.to()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    my_device = torch.device('cuda')\n",
    "else:\n",
    "    my_device = torch.device('cpu')\n",
    "print('Device: {}'.format(my_device))\n",
    "\n",
    "y = torch.rand(2, 2)\n",
    "y = y.to(my_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если в вычислениях участвуют несколько тензоров, то нужно быть уверенным, что все они находятся на одном и том же устройстве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected one of cpu, cuda, xpu, mkldnn, opengl, opencl, ideep, hip, ve, ort, mlc, xla, lazy, vulkan, meta, hpu device type at start of device string: gpu",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [139]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     z \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m y  \u001b[38;5;66;03m# exception will be thrown\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected one of cpu, cuda, xpu, mkldnn, opengl, opencl, ideep, hip, ve, ort, mlc, xla, lazy, vulkan, meta, hpu device type at start of device string: gpu"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 2)\n",
    "y = torch.rand(2, 2, device='gpu')\n",
    "try:\n",
    "    z = x + y  # exception will be thrown\n",
    "except Exception as e:\n",
    "    print(f\"Error occured : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с размерностями `torch.tensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как правило, модели в PyTorch на вход принимают тензоры определенной размерности. Например, большинство предобученных сверточных нейросетей использюут в качестве входа тензоры размерности (N, 3, 226, 226), где N - кол-во картинок в батче. Чтобы подать на вход такой сети одну картинку, ее нужно привести в данному формату входа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 226, 226])\n",
      "torch.Size([1, 3, 226, 226])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3, 226, 226)\n",
    "b = a.unsqueeze(0)\n",
    "\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим еще несколько примеров схлопывания и расхлопывания размерностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "tensor([[0.3277, 0.5210, 0.7349, 0.7823, 0.8637, 0.1891, 0.3952, 0.9176, 0.8960,\n",
      "         0.4887, 0.8625, 0.6191, 0.9935, 0.1844, 0.6138, 0.6854, 0.0438, 0.0636,\n",
      "         0.2884, 0.4362]])\n",
      "torch.Size([20])\n",
      "tensor([0.3277, 0.5210, 0.7349, 0.7823, 0.8637, 0.1891, 0.3952, 0.9176, 0.8960,\n",
      "        0.4887, 0.8625, 0.6191, 0.9935, 0.1844, 0.6138, 0.6854, 0.0438, 0.0636,\n",
      "        0.2884, 0.4362])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(1, 20)\n",
    "print(a.shape)\n",
    "print(a)\n",
    "\n",
    "b = a.squeeze(0)\n",
    "print(b.shape)\n",
    "print(b)\n",
    "\n",
    "c = torch.rand(2, 2)\n",
    "print(c.shape)\n",
    "\n",
    "d = c.squeeze(0)\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разрешено производить `squeeze`(cхлопывание) размерностей = 1, симметрично `unsqueeze`(расхлопываение) создает доп-ную размерность равную 1.\n",
    "Рассмотрим пример, когда `unsqueeze` позволяет применить операцию broadcasting'a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occured : The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 2\n",
      "torch.Size([3, 1])\n",
      "tensor([[[0.3851, 0.3851],\n",
      "         [0.0732, 0.0732],\n",
      "         [0.3118, 0.3118]],\n",
      "\n",
      "        [[0.3851, 0.3851],\n",
      "         [0.0732, 0.0732],\n",
      "         [0.3118, 0.3118]],\n",
      "\n",
      "        [[0.3851, 0.3851],\n",
      "         [0.0732, 0.0732],\n",
      "         [0.3118, 0.3118]],\n",
      "\n",
      "        [[0.3851, 0.3851],\n",
      "         [0.0732, 0.0732],\n",
      "         [0.3118, 0.3118]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(4, 3, 2)\n",
    "b = torch.rand(   3)     # trying to multiply a * b will give a runtime error\n",
    "try:\n",
    "    print(a * b)\n",
    "except Exception as e:\n",
    "    print(f\"Error occured : {e}\")\n",
    "c = b.unsqueeze(1)       # change to a 2-dimensional tensor, adding new dim at the end\n",
    "print(c.shape)\n",
    "print(a * c)             # broadcasting works again!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть так же возможность использовать inplace методы squeeze/unsqueeze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 226, 226])\n",
      "torch.Size([1, 3, 226, 226])\n"
     ]
    }
   ],
   "source": [
    "batch_me = torch.rand(3, 226, 226)\n",
    "print(batch_me.shape)\n",
    "batch_me.unsqueeze_(0)\n",
    "print(batch_me.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Операция `reshape` позволяет изменить размерности тензора произволными образом, сохранив кол-во значений тензора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 20, 20])\n",
      "torch.Size([2400])\n",
      "torch.Size([2400])\n"
     ]
    }
   ],
   "source": [
    "output3d = torch.rand(6, 20, 20)\n",
    "print(output3d.shape)\n",
    "\n",
    "input1d = output3d.reshape(6 * 20 * 20)\n",
    "print(input1d.shape)\n",
    "\n",
    "# can also call it as a method on the torch module:\n",
    "print(torch.reshape(output3d, (6 * 20 * 20,)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Связь `torch.tensor` c `numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch позволяет создавать тензоры непосредственно из имеющихся np.array объектов. Более того, torch.tensor будет указывать на память выделенную первоначально в numpy.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "Use same memory : True\n"
     ]
    }
   ],
   "source": [
    "numpy_array = np.ones((2, 3))\n",
    "print(numpy_array)\n",
    "\n",
    "pytorch_tensor = torch.from_numpy(numpy_array)\n",
    "print(pytorch_tensor)\n",
    "\n",
    "print(f\"Use same memory : {pytorch_tensor.data_ptr() == numpy_array.ctypes.data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обратную сторону `torch` -> `numpy` преобразование так же работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1874, 0.3136, 0.7793],\n",
      "        [0.8340, 0.3402, 0.9330]])\n",
      "[[0.18740034 0.31359702 0.77929854]\n",
      " [0.834021   0.3401633  0.9329737 ]]\n"
     ]
    }
   ],
   "source": [
    "pytorch_rand = torch.rand(2, 3)\n",
    "print(pytorch_rand)\n",
    "\n",
    "numpy_rand = pytorch_rand.numpy()\n",
    "print(numpy_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
